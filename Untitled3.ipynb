{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP30PlbA3gbqGdClJ2s1pCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nivriti-ctrl/CODECRAFT_GA_03/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U0TaBxhl5LPu"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_text = \"\"\"\n",
        "Markov chains are a powerful statistical tool.\n",
        "They predict the next state based on the current state.\n",
        "This can be used for text generation and many other applications.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lbDVaJ-s5XER"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_markov_chain(text, n=2):\n",
        "    \"\"\"\n",
        "    Build a Markov Chain model.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The input text.\n",
        "        n (int): The size of the n-gram (default: 2 for bigrams).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary representing the Markov Chain.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    markov_chain = defaultdict(list)\n",
        "\n",
        "    # Create n-grams\n",
        "    for i in range(len(words) - n):\n",
        "        key = tuple(words[i:i+n-1])  # Create a tuple for the key\n",
        "        next_word = words[i+n-1]    # Get the next word\n",
        "        markov_chain[key].append(next_word)\n",
        "\n",
        "    return markov_chain\n",
        "\n",
        "# Build the model\n",
        "markov_model = build_markov_chain(training_text, n=2)"
      ],
      "metadata": {
        "id": "nRx_kWJT5xan"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vtH2Air157jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(chain, n=2, length=50):\n",
        "    \"\"\"\n",
        "    Generate text using a Markov Chain model.\n",
        "\n",
        "    Parameters:\n",
        "        chain (dict): The Markov Chain model.\n",
        "        n (int): The size of the n-gram (default: 2 for bigrams).\n",
        "        length (int): Number of words to generate.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text.\n",
        "    \"\"\"\n",
        "    # Choose a random starting point\n",
        "    key = random.choice(list(chain.keys()))\n",
        "    result = list(key)\n",
        "\n",
        "    for _ in range(length - n + 1):\n",
        "        if key not in chain:\n",
        "            break\n",
        "        next_word = random.choice(chain[key])\n",
        "        result.append(next_word)\n",
        "        key = tuple(result[-(n-1):])  # Update key with the latest n-1 words\n",
        "\n",
        "    return ' '.join(result)\n",
        "\n",
        "# Generate text\n",
        "generated_text = generate_text(markov_model, n=2, length=50)\n",
        "print(\"Generated Text:\\n\", generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPNZTKMi50DF",
        "outputId": "8e87ab57-b94d-4bd8-bb54-1ea7875f4dea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            " based on the next state based on the current state. This can be used for text generation and many other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Downloading a public domain book (e.g., \"Alice's Adventures in Wonderland\")\n",
        "!wget https://www.gutenberg.org/files/11/11-0.txt -O training_text.txt\n",
        "\n",
        "# Read the downloaded file\n",
        "with open('training_text.txt', 'r', encoding='utf-8') as file:\n",
        "    training_text = file.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5XckZFA6ZWR",
        "outputId": "ee72052f-ac47-423e-ae83-721ac9fd58b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-26 09:20:38--  https://www.gutenberg.org/files/11/11-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154573 (151K) [text/plain]\n",
            "Saving to: ‘training_text.txt’\n",
            "\n",
            "training_text.txt   100%[===================>] 150.95K   837KB/s    in 0.2s    \n",
            "\n",
            "2025-01-26 09:20:39 (837 KB/s) - ‘training_text.txt’ saved [154573/154573]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "markov_model = build_markov_chain(training_text, n=3)\n",
        "generated_text = generate_text(markov_model, n=3, length=100)"
      ],
      "metadata": {
        "id": "dc6VeuAs6deZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "training_text = preprocess_text(training_text)"
      ],
      "metadata": {
        "id": "6LH4OSSN6i8Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_weighted_markov_chain(text, n=2):\n",
        "    words = text.split()\n",
        "    markov_chain = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # Create n-grams\n",
        "    for i in range(len(words) - n):\n",
        "        key = tuple(words[i:i+n-1])\n",
        "        next_word = words[i+n-1]\n",
        "        markov_chain[key][next_word] += 1\n",
        "\n",
        "    # Convert counts to probabilities\n",
        "    weighted_chain = {key: dict(value) for key, value in markov_chain.items()}\n",
        "    return weighted_chain\n",
        "\n",
        "markov_model = build_weighted_markov_chain(training_text, n=3)\n",
        "\n",
        "def generate_text_weighted(chain, n=2, length=50):\n",
        "    key = random.choice(list(chain.keys()))\n",
        "    result = list(key)\n",
        "\n",
        "    for _ in range(length - n + 1):\n",
        "        if key not in chain:\n",
        "            break\n",
        "        choices, weights = zip(*chain[key].items())\n",
        "        next_word = random.choices(choices, weights=weights)[0]\n",
        "        result.append(next_word)\n",
        "        key = tuple(result[-(n-1):])\n",
        "\n",
        "    return ' '.join(result)\n",
        "\n",
        "generated_text = generate_text_weighted(markov_model, n=3, length=100)\n",
        "print(\"Generated Text:\\n\", generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wB_7wUr6q77",
        "outputId": "3c3c6749-fb74-482c-c1d1-6c1ebc2171b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            " of serpent thats all i almost wish id gone to see it pop down a large plate came skimming out straight at the top of his pocket and pulled out a box of comfits luckily the salt water had not gone we know it to her in an undertone importantunimportantunimportantimportant as if she should meet the real mary ann and be quick about it and as the things i used to come out among the people near the three gardeners but she was not easy to take the place of the _what_ said the hatter you _must_ have meant some\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('generated_text.txt', 'w') as file:\n",
        "    file.write(generated_text)"
      ],
      "metadata": {
        "id": "nbhaGQ1m6tvt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('generated_text.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3R7h2xnX61_p",
        "outputId": "e1bc12be-073b-4291-f6dc-bd98b06cb6fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24b4afa2-3093-4dac-a6bf-92fc327b1ded\", \"generated_text.txt\", 507)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}